{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBbWMn9ebmi8"
      },
      "source": [
        "# **Maestría en Inteligencia Artificial Aplicada**\n",
        "\n",
        "## **Curso: Inteligencia Artificial y Aprendizaje Automático**\n",
        "\n",
        "### Tecnológico de Monterrey\n",
        "\n",
        "### Prof Luis Eduardo Falcón Morales\n",
        "\n",
        "## **Actividad de las Semanas 5 y 6**\n",
        "### **Problema de asignación de créditos: South German Dataset.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiwEw8XsZG2W"
      },
      "source": [
        "## **Nombres y matrículas:**\n",
        "\n",
        "\n",
        "🔹 Jossie Paola Jiménez Rivera   ➡️ A01795961\n",
        "\n",
        "🔹 Javier Augusto Rebull Saucedo ➡️ A01795838\n",
        "\n",
        "🔹 Nancy Teresa Zapién García    ➡️ A01795907\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUxxkjE6shkH"
      },
      "source": [
        "# **Parte I: Partición, análisis y pre-procesamiento de los datos.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a08Di3GjkL1Y"
      },
      "source": [
        "## **Ejercicio 1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6VGEpE4SblfD"
      },
      "outputs": [],
      "source": [
        "# Aquí deberás incluir todas las librerías que requieras durante esta actividad:\n",
        "\n",
        "#Para cargar archivos\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Para manipular datos\n",
        "import numpy as np  # Biblioteca para realizar operaciones numéricas y trabajar con arreglos multidimensionales.\n",
        "import pandas as pd  # Biblioteca para manipulación y análisis de datos, ofrece estructuras como DataFrame y Series.\n",
        "\n",
        "# Ejercicio 3.\n",
        "from sklearn.model_selection import train_test_split  # Función para dividir los datos en conjuntos de entrenamiento y prueba.\n",
        "\n",
        "# Ejercicio 5.\n",
        "from sklearn.pipeline import Pipeline  # Clase que ayuda a ensamblar varios pasos de procesamiento y modelado en una secuencia.\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, OrdinalEncoder  # Herramientas para la transformación de características: escalado y codificación de variables categóricas.\n",
        "from sklearn.compose import ColumnTransformer  # Permite aplicar diferentes transformaciones a diferentes columnas en un conjunto de datos.\n",
        "from sklearn.impute import SimpleImputer  # Rellena valores faltantes en los datos según una estrategia específica (como la media, mediana, moda).\n",
        "\n",
        "# Ejercicio 7.\n",
        "from sklearn.linear_model import LogisticRegression  # Modelo de regresión logística para problemas de clasificación binaria y multiclase.\n",
        "from sklearn.tree import DecisionTreeClassifier  # Modelo de clasificación basado en árboles de decisión.\n",
        "from sklearn.neighbors import KNeighborsClassifier  # Algoritmo de clasificación basado en vecinos más cercanos.\n",
        "from sklearn.ensemble import RandomForestClassifier  # Modelo de ensamble basado en múltiples árboles de decisión para mejorar la precisión.\n",
        "from xgboost import XGBClassifier  # Modelo de clasificación de gradiente boosting basado en árboles, conocido por su alto rendimiento.\n",
        "from sklearn.neural_network import MLPClassifier  # Modelo de red neuronal multicapa para clasificación.\n",
        "from sklearn.svm import SVC  # Máquina de vectores de soporte para clasificación.\n",
        "\n",
        "# Para conjuntos desbalanceados\n",
        "from imblearn.over_sampling import SMOTE, KMeansSMOTE  # Técnicas de sobremuestreo para equilibrar clases desbalanceadas en problemas de clasificación.\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold, cross_validate  # Métodos para validación cruzada y división estratificada repetida en conjuntos de datos.\n",
        "from sklearn.metrics import make_scorer  # Función que permite crear métricas personalizadas para la evaluación de modelos.\n",
        "from imblearn.metrics import geometric_mean_score  # Métrica de rendimiento para conjuntos de datos desbalanceados, basada en la media geométrica."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "K3gUzoM3iRkt"
      },
      "outputs": [],
      "source": [
        "# Si se desean comentar algunos de los Warnings.\n",
        "import warnings  # Módulo para controlar los warnings que surgen durante la ejecución del código.\n",
        "warnings.filterwarnings('ignore')  # Esta línea desactiva la visualización de warnings en el código. Se usa para evitar que se impriman mensajes de advertencia que no sean críticos y así tener una salida"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 725
        },
        "id": "ppyf8TTgb9zq",
        "outputId": "71e97a0c-4ff0-4004-9a5d-cd1163b9d5a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                            0     1    2     3     4\n",
              "status                      1     1    2     1     1\n",
              "duration                   18     9   12    12    12\n",
              "credit_history              4     4    2     4     4\n",
              "purpose                     2     0    9     0     0\n",
              "amount                   1049  2799  841  2122  2171\n",
              "savings                     1     1    2     1     1\n",
              "employment_duration         2     3    4     3     3\n",
              "installment_rate            4     2    2     3     4\n",
              "personal_status_sex         2     3    2     3     3\n",
              "other_debtors               1     1    1     1     1\n",
              "present_residence           4     2    4     2     4\n",
              "property                    2     1    1     1     2\n",
              "age                        21    36   23    39    38\n",
              "other_installment_plans     3     3    3     3     1\n",
              "housing                     1     1    1     1     2\n",
              "number_credits              1     2    1     2     2\n",
              "job                         3     3    2     2     2\n",
              "people_liable               2     1    2     1     2\n",
              "telephone                   1     1    1     1     1\n",
              "foreign_worker              2     2    2     1     1\n",
              "credit_risk                 1     1    1     1     1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dbbe65aa-9c88-4bdc-b526-5abef20e3c50\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>status</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>duration</th>\n",
              "      <td>18</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>credit_history</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>purpose</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>amount</th>\n",
              "      <td>1049</td>\n",
              "      <td>2799</td>\n",
              "      <td>841</td>\n",
              "      <td>2122</td>\n",
              "      <td>2171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>savings</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>employment_duration</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>installment_rate</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>personal_status_sex</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>other_debtors</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>present_residence</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>property</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age</th>\n",
              "      <td>21</td>\n",
              "      <td>36</td>\n",
              "      <td>23</td>\n",
              "      <td>39</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>other_installment_plans</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>housing</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>number_credits</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>job</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>people_liable</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>telephone</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>foreign_worker</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>credit_risk</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dbbe65aa-9c88-4bdc-b526-5abef20e3c50')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dbbe65aa-9c88-4bdc-b526-5abef20e3c50 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dbbe65aa-9c88-4bdc-b526-5abef20e3c50');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-479039f9-e5a5-4057-b87e-aef5515b99f6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-479039f9-e5a5-4057-b87e-aef5515b99f6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-479039f9-e5a5-4057-b87e-aef5515b99f6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Carga y renombra los nombres de las columnas del alemán al inglés y desplegamos\n",
        "# de nuevo el DataFrame para ver el resultado obtenido:\n",
        "\n",
        "# ************* Incluye aquí tu código:*****************************\n",
        "# NOTA: Tanto aquí como en lo sucesivo, \"None\" puede indicar una o varias líneas de código.\n",
        "\n",
        "drive.mount('/content/drive')  # Monta Google Drive para acceder a archivos desde Colab.\n",
        "\n",
        "DIR = '/content/drive/MyDrive/TecMTY/septiembre noviembre 2024/IA y ML/Semana 5 y 6'\n",
        "os.chdir(DIR)  # Cambia el directorio a la ubicación del archivo en Google Drive.\n",
        "\n",
        "# Lectura del archivo .asc\n",
        "df = pd.read_csv('SouthGermanCredit.asc', sep=' ')  # Lee el archivo de crédito alemán con separación por espacio.\n",
        "\n",
        "# Renombra columnas de Alemán a Inglés\n",
        "columns = [\n",
        "    'status',                  # Status (laufkont)\n",
        "    'duration',                # Duration (laufzeit)\n",
        "    'credit_history',          # Credit history (moral)\n",
        "    'purpose',                 # Purpose (verw)\n",
        "    'amount',                  # Amount (hoehe)\n",
        "    'savings',                 # Savings (sparkont)\n",
        "    'employment_duration',     # Employment duration (beszeit)\n",
        "    'installment_rate',        # Installment rate (rate)\n",
        "    'personal_status_sex',     # Personal status sex (famges)\n",
        "    'other_debtors',           # Other debtors (buerge)\n",
        "    'present_residence',       # Present residence (wohnzeit)\n",
        "    'property',                # Property (verm)\n",
        "    'age',                     # Age (alter)\n",
        "    'other_installment_plans', # Other installment plans (weitkred)\n",
        "    'housing',                 # Housing (wohn)\n",
        "    'number_credits',          # Number credits (bishkred)\n",
        "    'job',                     # Job (beruf)\n",
        "    'people_liable',           # People liable (pers)\n",
        "    'telephone',               # Telephone (telef)\n",
        "    'foreign_worker',          # Foreign worker (gastarb)\n",
        "    'credit_risk'              # Credit risk (kredit)\n",
        "]\n",
        "\n",
        "# Guarda nuevos nombres de las columnas al DataFrame\n",
        "df.columns = columns  # Asigna la lista 'columns' como nombres de las columnas del DataFrame.\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************\n",
        "\n",
        "df.head().T  # Muestra las primeras filas del DataFrame transpuestas para visualizar mejor los nombres de las columnas y valores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LckYCS8SlnFo"
      },
      "source": [
        "## **Ejercicio 2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tlg8jYbnlqNA",
        "outputId": "3f64842c-cb84-4958-8bed-9cfd06ba31e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "credit_risk\n",
            "0    700\n",
            "1    300\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Realiza a continuación una transformación para que la clase negativa (buen cliente)\n",
        "# quede con el valor de 0 y la clase positiva (mal cliente) quede con el valor de 1.\n",
        "\n",
        "# ************* Incluye aquí tu código:*****************************\n",
        "# Intercambia los valores de la columna 'credit_risk': los buenos clientes (0) pasan a ser 1, y los malos clientes (1) pasan a ser 0.\n",
        "df['credit_risk'] = df['credit_risk'].replace({0:1, 1:0})\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************\n",
        "\n",
        "print(df['credit_risk'].value_counts())  # Muestra el conteo de valores de la columna 'credit_risk' después de la transformación para verificar el cambio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQx2lbzTkEsQ"
      },
      "source": [
        "## **Ejercicio 3**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TP5-zdWVczhy",
        "outputId": "d3601a2b-95db-49b1-affc-e0456cea6840"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensiones:\n",
            "Entrenamiento: (700, 20) (700,)\n",
            "Prueba: (300, 20) (300,)\n",
            "\n",
            "Porcentaje clases Positiva:70.00%, y Negativa:30.00%\n"
          ]
        }
      ],
      "source": [
        "# Realiza una partición solicitada de entrenamiento y prueba.\n",
        "# Los nombres de los conjuntos deberán ser como se indican en los print de abajo:\n",
        "\n",
        "# ************* Incluye aquí tu código:*****************************\n",
        "\n",
        "X = df.drop(columns='credit_risk')  # Características (variables independientes) del conjunto de datos, excluyendo la variable de salida 'credit_risk'.\n",
        "y = df['credit_risk']  # Variable de salida (variable dependiente), en este caso, 'credit_risk'.\n",
        "\n",
        "# El artículo sugiere una partición de (70:30), Entrenamiento 70% y Prueba 30%\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.3, stratify=y, random_state=1)\n",
        "# Se realiza la división en conjuntos de entrenamiento y prueba, manteniendo la proporción de las clases (stratify) y con un random_state para reproducibilidad.\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************\n",
        "\n",
        "# Mostremos las dimensiones de la partición generada:\n",
        "print(\"Dimensiones:\")  # Se muestran las dimensiones de los conjuntos de entrenamiento y prueba.\n",
        "print(\"Entrenamiento:\", Xtrain.shape, ytrain.shape)  # Dimensiones del conjunto de entrenamiento.\n",
        "print(\"Prueba:\", Xtest.shape, ytest.shape)  # Dimensiones del conjunto de prueba.\n",
        "\n",
        "# Y el porcentaje de cada clase de la variable de salida:\n",
        "tmp = ytrain.sum() / ytrain.shape[0]  # Cálculo del porcentaje de la clase positiva en el conjunto de entrenamiento.\n",
        "print(\"\\nPorcentaje clases Positiva:%.2f%%, y Negativa:%.2f%%\" % (100*(1-tmp), tmp*100))  # Se imprime el porcentaje de clase positiva y negativa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiiSX3_MdAvr"
      },
      "source": [
        "### **Con base al porcentaje de los niveles de la variable de salida ¿podemos decir que tenemos un problema de datos desbalanceado? ¿Por qué?**\n",
        "\n",
        "++++++++ Inicia la sección de agregar texto: +++++++++++\n",
        "\n",
        "Con base en los porcentajes obtenidos, podemos confirmar que existe un desbalance en el conjunto de datos. Del 100% de los datos, el 70% corresponde a la clase positiva (**malos clientes**) y el 30% a la clase negativa (**buenos clientes**). Este desbalance puede impactar negativamente el rendimiento de los modelos de aprendizaje automático, ya que tienden a ser más efectivos en identificar la clase mayoritaria (malos clientes), mientras que su precisión al predecir la clase minoritaria (buenos clientes) disminuye.\n",
        "\n",
        "Cuando se trabaja con datos desbalanceados, es común que el modelo se ajuste para predecir mejor la clase con mayor representación (0), lo que puede llevar a errores significativos al identificar casos de la clase minoritaria (1). Esto representa un reto importante para la construcción de modelos que busquen un buen equilibrio entre ambas clases.\n",
        "\n",
        "Para mitigar este problema, es crucial aplicar técnicas adecuadas como el submuestreo de la clase mayoritaria, el sobremuestreo de la clase minoritaria, o el uso de algoritmos diseñados para manejar conjuntos de datos desbalanceados. Con estas estrategias, podemos mejorar la capacidad del modelo para identificar correctamente los clientes de la clase minoritaria sin comprometer su rendimiento general.\n",
        "\n",
        "### ++++++++ Termina la sección de agregar texto: +++++++++++"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocmGcSC2j_2x"
      },
      "source": [
        "## **Ejercicio 4**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5J2kIzLYHPZP"
      },
      "outputs": [],
      "source": [
        "# De acuerdo a la información de la Tabla 3 del artículo de la IEEE\n",
        "# define las variables correspondientes que se indican a continuación:\n",
        "\n",
        "# ************* Incluye aquí tu código:*****************************\n",
        "\n",
        "# Variables numéricas:\n",
        "lista_paper_num = [\n",
        "    'duration',        # Duración del crédito\n",
        "    'amount',          # Monto total del crédito\n",
        "    'age',             # Edad del cliente\n",
        "    'peope_liable'     # Número de personas a cargo del cliente\n",
        "]\n",
        "# 4 variables numéricas\n",
        "\n",
        "# Variables ordinales:\n",
        "lista_paper_ord = [\n",
        "    'employment_duration',    # Duración del empleo del cliente\n",
        "    'installment_rate',       # Tasa de las cuotas del crédito\n",
        "    'present_residence',      # Tiempo de residencia en el domicilio actual\n",
        "    'property',               # Tipo de propiedad\n",
        "    'number_credits',         # Número de créditos anteriores\n",
        "    'job'                     # Ocupación del cliente\n",
        "]\n",
        "# 6 variables ordinales\n",
        "\n",
        "# Variables nominales:\n",
        "lista_paper_cat = [\n",
        "    'status',                 # Estado del crédito\n",
        "    'credit_history',         # Historial crediticio\n",
        "    'purpose',                # Propósito del crédito\n",
        "    'savings',                # Ahorros del cliente\n",
        "    'personal_status_sex',    # Estado civil y sexo\n",
        "    'other_debtors',          # Otros deudores o avales\n",
        "    'other_installment_plans',# Otros planes de cuotas\n",
        "    'housing',                # Tipo de vivienda\n",
        "    'telephone',              # Disponibilidad de teléfono\n",
        "    'foreign_worker'          # Si el cliente es trabajador extranjero\n",
        "]\n",
        "# 10 variables nominales (no se toma en cuenta 'credit_risk')\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zb5bE4WJj8Rw"
      },
      "source": [
        "## **Ejercicio 5**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NvNYiIp9weCm"
      },
      "outputs": [],
      "source": [
        "# Transformaciones que se aplicarán a las variables numéricas usando la clase Pipeline de sklearn:\n",
        "\n",
        "# ************* Incluye aquí tu código:*****************************\n",
        "\n",
        "# Variables numéricas:\n",
        "numericas_pipe = Pipeline([\n",
        "    (\"impute\", SimpleImputer(strategy=\"median\")),   # Imputar (rellenar) valores faltantes con la mediana de cada variable numérica.\n",
        "    (\"standardize\", MinMaxScaler())                 # Escalar los valores numéricos para que estén en un rango entre 0 y 1, usando MinMaxScaler.\n",
        "])\n",
        "numericas_pipe_nombres = ['duration', 'amount', 'age', 'people_liable']  # Lista de los nombres de las variables numéricas a transformar.\n",
        "\n",
        "# Variables categóricas-Nominales:\n",
        "nominales_pipe = Pipeline([\n",
        "    (\"impute\", SimpleImputer(strategy=\"most_frequent\")),  # Imputar valores faltantes con el valor más frecuente (moda) para variables nominales.\n",
        "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", drop=\"first\"))  # Codificación One-Hot, ignora categorías desconocidas y evita la colinealidad (drop=\"first\").\n",
        "])\n",
        "nominales_pipe_nombres = ['status', 'credit_history', 'purpose', 'savings',\n",
        "                          'personal_status_sex', 'other_debtors',\n",
        "                          'other_installment_plans', 'housing', 'telephone', 'foreign_worker']\n",
        "# Lista de los nombres de las variables categóricas nominales a transformar (excluye 'credit_risk').\n",
        "\n",
        "# Variables categóricas-ordinales:\n",
        "ordinales_pipe = Pipeline([\n",
        "    (\"impute\", SimpleImputer(strategy=\"most_frequent\")),  # Imputar valores faltantes con el valor más frecuente.\n",
        "    (\"encoder\", OrdinalEncoder())                        # Codificación ordinal, que asigna valores numéricos ordenados a las categorías.\n",
        "])\n",
        "ordinales_pipe_nombres = ['employment_duration', 'installment_rate', 'present_residence',\n",
        "                          'property', 'number_credits', 'job']\n",
        "# Lista de los nombres de las variables categóricas ordinales a transformar.\n",
        "\n",
        "# Conjunta las transformaciones de todo tipo de variable y\n",
        "# deja sin procesar aquellas que hayas decidido no transformar:\n",
        "columnasTransformer = ColumnTransformer(transformers=[\n",
        "    ('num', numericas_pipe, numericas_pipe_nombres),  # Aplica las transformaciones numéricas a las variables numéricas.\n",
        "    ('ord', ordinales_pipe, ordinales_pipe_nombres),  # Aplica las transformaciones ordinales a las variables categóricas ordinales.\n",
        "    ('nom', nominales_pipe, nominales_pipe_nombres)   # Aplica las transformaciones nominales a las variables categóricas nominales.\n",
        "], remainder='passthrough')  # Mantiene las columnas no especificadas sin procesar ('passthrough').\n",
        "\n",
        "# Explicación:\n",
        "# - Pipelines: Se utilizan para aplicar secuencias de transformaciones sobre conjuntos de variables. Por ejemplo,\n",
        "#   las variables numéricas primero rellenan valores faltantes con la mediana y luego se escalan.\n",
        "# - ColumnTransformer: Permite aplicar diferentes transformaciones a diferentes subconjuntos de variables\n",
        "#   (numéricas, ordinales y nominales) al mismo tiempo.\n",
        "# - 'remainder=\"passthrough\"': Indica que las columnas no especificadas en el ColumnTransformer no se transforman\n",
        "#   y se mantienen tal como están.\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJokj9Diyeu0"
      },
      "source": [
        "## **Ejercicio 6**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3lqBiH5wd1e",
        "outputId": "a9ca5a2e-3b1a-4ee5-b7ef-63dd718dedde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensión de las variables de entrada ANTES de las transformaciones: (1000, 20)\n",
            "Dimensión de las variables de entrada DESPUÉS de las transformaciones: (1000, 41)\n"
          ]
        }
      ],
      "source": [
        "# Como se va a utilizar Validación-Cruzada, concatena los conjuntos de entrenamiento y prueba\n",
        "# en uno nuevo conjunto aumentado que llamaremos trainval para utilizar como entrenamiento:\n",
        "\n",
        "# ************* Incluye aquí tu código:**************************\n",
        "\n",
        "# Se concatenan los conjuntos de entrenamiento (Xtrain, ytrain) y prueba (Xtest, ytest) para formar un único conjunto\n",
        "# combinado llamado Xtraintest y ytraintest. Esto es útil cuando se desea entrenar y validar un modelo con\n",
        "# todo el conjunto de datos disponible, aplicando Validación Cruzada.\n",
        "Xtraintest = pd.concat([Xtrain, Xtest], axis=0)  # Concatena las características (features) de los conjuntos de entrenamiento y prueba.\n",
        "ytraintest = pd.concat([ytrain, ytest], axis=0)  # Concatena las etiquetas (target) de los conjuntos de entrenamiento y prueba.\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************\n",
        "\n",
        "# Veamos cuántas variables nuevas se introducen con las transformaciones One-Hot-Encoding:\n",
        "Xtmp = Xtraintest.copy()  # Se realiza una copia de Xtraintest para aplicar las transformaciones y no modificar los datos originales.\n",
        "tmp = columnasTransformer.fit_transform(Xtmp)  # Se ajusta y transforma el conjunto de datos usando el ColumnTransformer, que aplica One-Hot-Encoding y otras transformaciones.\n",
        "print(\"Dimensión de las variables de entrada ANTES de las transformaciones:\", Xtmp.shape)  # Imprime la dimensión original del conjunto de datos antes de las transformaciones.\n",
        "print(\"Dimensión de las variables de entrada DESPUÉS de las transformaciones:\", tmp.shape)  # Imprime la dimensión del conjunto de datos después de aplicar las transformaciones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZxyRbHL0gNF"
      },
      "source": [
        "## **Ejercicio 7**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hdi7AAtwd5G",
        "outputId": "9ebe6f3d-5363-4b94-977c-978226cef4a6",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> LR\n",
            "\t test_miaccuracy 0.817 (0.029)\n",
            "\t train_miaccuracy 0.832 (0.007)\n",
            "\t test_miprecision 0.827 (0.034)\n",
            "\t train_miprecision 0.845 (0.010)\n",
            "\t test_mirecall 0.803 (0.036)\n",
            "\t train_mirecall 0.813 (0.007)\n",
            "\t test_mifi 0.814 (0.030)\n",
            "\t train_mifi 0.829 (0.007)\n",
            "\t test_miauc 0.903 (0.021)\n",
            "\t train_miauc 0.921 (0.005)\n",
            "\t test_migmean 0.816 (0.030)\n",
            "\t train_migmean 0.832 (0.007)\n",
            ">> kNN\n",
            "\t test_miaccuracy 0.795 (0.020)\n",
            "\t train_miaccuracy 0.817 (0.006)\n",
            "\t test_miprecision 0.840 (0.022)\n",
            "\t train_miprecision 0.865 (0.011)\n",
            "\t test_mirecall 0.731 (0.032)\n",
            "\t train_mirecall 0.751 (0.008)\n",
            "\t test_mifi 0.781 (0.023)\n",
            "\t train_mifi 0.804 (0.006)\n",
            "\t test_miauc 0.881 (0.022)\n",
            "\t train_miauc 0.907 (0.005)\n",
            "\t test_migmean 0.793 (0.021)\n",
            "\t train_migmean 0.814 (0.006)\n",
            ">> DTree\n",
            "\t test_miaccuracy 0.792 (0.026)\n",
            "\t train_miaccuracy 0.888 (0.009)\n",
            "\t test_miprecision 0.802 (0.034)\n",
            "\t train_miprecision 0.910 (0.021)\n",
            "\t test_mirecall 0.777 (0.039)\n",
            "\t train_mirecall 0.862 (0.030)\n",
            "\t test_mifi 0.789 (0.027)\n",
            "\t train_mifi 0.885 (0.010)\n",
            "\t test_miauc 0.853 (0.023)\n",
            "\t train_miauc 0.967 (0.004)\n",
            "\t test_migmean 0.791 (0.026)\n",
            "\t train_migmean 0.887 (0.009)\n",
            ">> RF\n",
            "\t test_miaccuracy 0.819 (0.024)\n",
            "\t train_miaccuracy 0.971 (0.005)\n",
            "\t test_miprecision 0.899 (0.019)\n",
            "\t train_miprecision 1.000 (0.000)\n",
            "\t test_mirecall 0.719 (0.051)\n",
            "\t train_mirecall 0.942 (0.009)\n",
            "\t test_mifi 0.798 (0.033)\n",
            "\t train_mifi 0.970 (0.005)\n",
            "\t test_miauc 0.907 (0.018)\n",
            "\t train_miauc 0.999 (0.000)\n",
            "\t test_migmean 0.813 (0.028)\n",
            "\t train_migmean 0.970 (0.005)\n",
            ">> XGBoost\n",
            "\t test_miaccuracy 0.818 (0.023)\n",
            "\t train_miaccuracy 0.971 (0.005)\n",
            "\t test_miprecision 0.855 (0.028)\n",
            "\t train_miprecision 0.986 (0.004)\n",
            "\t test_mirecall 0.766 (0.034)\n",
            "\t train_mirecall 0.954 (0.009)\n",
            "\t test_mifi 0.808 (0.026)\n",
            "\t train_mifi 0.970 (0.005)\n",
            "\t test_miauc 0.906 (0.019)\n",
            "\t train_miauc 0.997 (0.001)\n",
            "\t test_migmean 0.816 (0.023)\n",
            "\t train_migmean 0.970 (0.005)\n",
            ">> MLP\n",
            "\t test_miaccuracy 0.813 (0.026)\n",
            "\t train_miaccuracy 0.831 (0.008)\n",
            "\t test_miprecision 0.817 (0.028)\n",
            "\t train_miprecision 0.839 (0.013)\n",
            "\t test_mirecall 0.808 (0.036)\n",
            "\t train_mirecall 0.819 (0.011)\n",
            "\t test_mifi 0.812 (0.027)\n",
            "\t train_mifi 0.829 (0.007)\n",
            "\t test_miauc 0.903 (0.021)\n",
            "\t train_miauc 0.921 (0.005)\n",
            "\t test_migmean 0.813 (0.026)\n",
            "\t train_migmean 0.831 (0.008)\n",
            ">> SVM\n",
            "\t test_miaccuracy 0.823 (0.030)\n",
            "\t train_miaccuracy 0.840 (0.007)\n",
            "\t test_miprecision 0.840 (0.033)\n",
            "\t train_miprecision 0.859 (0.010)\n",
            "\t test_mirecall 0.798 (0.038)\n",
            "\t train_mirecall 0.814 (0.011)\n",
            "\t test_mifi 0.818 (0.031)\n",
            "\t train_mifi 0.836 (0.007)\n",
            "\t test_miauc 0.903 (0.022)\n",
            "\t train_miauc 0.919 (0.005)\n",
            "\t test_migmean 0.822 (0.030)\n",
            "\t train_migmean 0.840 (0.007)\n"
          ]
        }
      ],
      "source": [
        "# Definimos a continuación la función que llamamos \"mis_modelos\" que incluye\n",
        "# todos los modelos que deseamos comparar en el ejercicio.\n",
        "\n",
        "def mis_modelos():\n",
        "    # Inicializamos listas para almacenar los modelos y sus nombres\n",
        "    modelos, nombres = list(), list()\n",
        "\n",
        "    # ************* Incluye aquí tu código:**************************\n",
        "    #\n",
        "    # Deberás incluir en cada modelo los argumentos que consideres\n",
        "    # adecuados para que cada uno converja y no esté sobreentrenado\n",
        "    # con respecto a la métrica de la exactitud (accuracy).\n",
        "\n",
        "    # Regresión Logística - Logistic Regression (LR):\n",
        "    modelos.append(LogisticRegression(penalty='elasticnet',\n",
        "                                      solver='saga',\n",
        "                                      tol=0.0001,         # Tolerancia\n",
        "                                      fit_intercept=True,\n",
        "                                      max_iter=2000,\n",
        "                                      C=10,\n",
        "                                      l1_ratio=0.34,\n",
        "                                      random_state=1))\n",
        "    nombres.append('LR')\n",
        "\n",
        "    # k-Vecinos más Cercanos - k-Nearest-Neighbors (kNN):\n",
        "    modelos.append(KNeighborsClassifier(n_neighbors=20,\n",
        "                                        p=1,\n",
        "                                        leaf_size=35,\n",
        "                                        n_jobs=-1,\n",
        "                                        weights=\"uniform\"))\n",
        "    nombres.append('kNN')\n",
        "\n",
        "    # Árbol de Decisiones - DecisionTree (DTree):\n",
        "    modelos.append(DecisionTreeClassifier(criterion=\"entropy\",\n",
        "                                          max_depth=10,\n",
        "                                          min_samples_split=15,\n",
        "                                          random_state=1))\n",
        "    nombres.append('DTree')\n",
        "\n",
        "    # Bosque Aleatorio - RandomForest (RF):\n",
        "    modelos.append(RandomForestClassifier(n_estimators=200,\n",
        "                                          criterion=\"entropy\",\n",
        "                                          max_features=\"sqrt\",\n",
        "                                          random_state=1,\n",
        "                                          max_depth=10))\n",
        "    nombres.append('RF')\n",
        "\n",
        "    # XGBoost:\n",
        "    modelos.append(XGBClassifier(random_state=1,\n",
        "                                 tree_method=\"hist\",\n",
        "                                 learning_rate=0.05,\n",
        "                                 max_depth=7))\n",
        "    nombres.append('XGBoost')\n",
        "\n",
        "    # Red Neuronal de Perceptrón Multicapa - MLP:\n",
        "    modelos.append(MLPClassifier(solver=\"adam\",\n",
        "                                 random_state=1,\n",
        "                                 hidden_layer_sizes=32,\n",
        "                                 activation=\"identity\",\n",
        "                                 max_iter=2500,\n",
        "                                 alpha=0.001))\n",
        "    nombres.append('MLP')\n",
        "\n",
        "    # Máquina de Vectores de Soporte - SVM:\n",
        "    modelos.append(SVC(C=14,\n",
        "                       kernel=\"linear\",\n",
        "                       tol=0.0001))\n",
        "    nombres.append('SVM')\n",
        "\n",
        "    return modelos, nombres\n",
        "\n",
        "# Técnica de submuestreo (undersampling) y/o sobremuestreo (oversampling) utilizada:\n",
        "mi_uoSampling = KMeansSMOTE(random_state=1, k_neighbors=6, n_jobs=-1)\n",
        "\n",
        "# Aplicamos el sobremuestreo a los datos de entrenamiento:\n",
        "Xtv_uo, ytv_uo = mi_uoSampling.fit_resample(Xtraintest, ytraintest)\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *******************\n",
        "\n",
        "# Entrenamos cada uno de los modelos y desplegamos las métricas de Train y Validation (Val).\n",
        "# NOTA: Observa que el método de Validación-Cruzada llama a los resultados de \"validation\" como \"test\".\n",
        "\n",
        "modelos, nombres = mis_modelos()  # Llamamos a la función para obtener los modelos y nombres\n",
        "resultados = list()\n",
        "\n",
        "# Iteramos sobre cada modelo para entrenarlo y evaluar su rendimiento.\n",
        "for i in range(len(modelos)):\n",
        "    # Definimos el pipeline con las transformaciones y los modelos\n",
        "    pipeline = Pipeline(steps=[('ct', columnasTransformer), ('m', modelos[i])])\n",
        "\n",
        "    # Aplicamos validación-cruzada con 5 divisiones repetidas 3 veces\n",
        "    micv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=5)\n",
        "\n",
        "    # Definimos las métricas que deseamos recuperar\n",
        "    mismetricas = {\n",
        "        'miaccuracy': 'accuracy',\n",
        "        'miprecision': 'precision',\n",
        "        'mirecall': 'recall',\n",
        "        'mifi': 'f1',\n",
        "        'miauc': 'roc_auc',\n",
        "        'migmean': make_scorer(geometric_mean_score)\n",
        "    }\n",
        "\n",
        "    # Entrenamos el modelo usando validación cruzada\n",
        "    scores = cross_validate(pipeline, Xtv_uo, ytv_uo, scoring=mismetricas, cv=micv, return_train_score=True)\n",
        "\n",
        "    # Guardamos los resultados del modelo para análisis posteriores\n",
        "    resultados.append(scores)\n",
        "\n",
        "    # Desplegamos las métricas para verificar posibles problemas de subentrenamiento o sobreentrenamiento\n",
        "    print('>> %s' % nombres[i])\n",
        "    for j, k in enumerate(list(scores.keys())):\n",
        "        if j > 1:\n",
        "            print('\\t %s %.3f (%.3f)' % (k, np.mean(scores[k]), np.std(scores[k])))\n",
        "\n",
        "# El código entrena cada uno de los modelos, aplica validación cruzada y muestra las métricas\n",
        "# para evaluar el rendimiento del modelo en los datos de entrenamiento y validación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JkGo57zMXqn"
      },
      "source": [
        "## **Ejercicio 8**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n04HnK-ZX4vl"
      },
      "source": [
        "### **Escribe tus conclusiones finales de la actividad.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iVH8hGAgy_N"
      },
      "source": [
        "++++++++ Inicia la sección de agregar texto: +++++++++++\n",
        "\n",
        "### **Conclusiones Finales de la Actividad:**\n",
        "\n",
        "En esta actividad se evaluaron diferentes modelos de aprendizaje automático y se implementaron técnicas de sobre-muestreo (SMOTE) para abordar el problema de desbalance de clases. El desbalance de clases, donde la clase mayoritaria (buenos clientes) representa el 70% y la clase minoritaria (malos clientes) el 30%, puede afectar negativamente el rendimiento de los modelos, ya que tienden a priorizar la clase mayoritaria.\n",
        "\n",
        "El sobre-muestreo, como SMOTE, añade ejemplos sintéticos a la clase minoritaria para equilibrar la distribución de clases sin perder datos de la clase mayoritaria. Aunque esta técnica es útil, puede incrementar los tiempos de entrenamiento y el uso de memoria, además de aumentar el riesgo de sobreajuste, especialmente en conjuntos de datos pequeños. Por otro lado, el submuestreo, que reduce la clase mayoritaria, es más eficiente en cuanto a memoria y tiempo, pero puede llevar a la pérdida de información valiosa, por lo que no es recomendable en datasets pequeños.\n",
        "\n",
        "\n",
        "-\n",
        "\n",
        "\n",
        "Los modelos implementados fueron:\n",
        "\n",
        "- **Regresión Logística (LR)**: Algoritmo supervisado para problemas de clasificación binaria que predice probabilidades según las características del conjunto de datos, aplicando una regresión lineal con una salida de 0 o 1.\n",
        "  \n",
        "- **k-Vecinos más Cercanos (kNN)**: Algoritmo utilizado para clasificación y regresión, que predice la variable de salida basada en los K vecinos más cercanos. El valor de K es clave para ajustar el modelo.\n",
        "\n",
        "- **Árbol de Decisión (DTree)**: Algoritmo de clasificación y regresión que divide el conjunto de datos en subconjuntos basados en características, creando un árbol de decisiones que facilita las predicciones.\n",
        "\n",
        "- **Bosque Aleatorio (RF)**: Algoritmo de ensamble que construye múltiples árboles de decisión en submuestras del conjunto de datos y promedia los resultados para mejorar la precisión y reducir el sobreajuste.\n",
        "\n",
        "- **Extreme Gradient Boosting (XGBoost)**: Método basado en árboles de decisión que mejora el rendimiento mediante el refuerzo de gradientes. Cada árbol se construye para corregir los errores del anterior, continuando hasta que los residuales se minimicen o se alcance el número máximo de iteraciones.\n",
        "\n",
        "- **Red Neuronal de Perceptrón Multicapa (MLP)**: Modelo inspirado en el funcionamiento del cerebro humano, compuesto por múltiples capas de neuronas conectadas que permiten el aprendizaje de patrones complejos.\n",
        "\n",
        "- **Máquina de Vectores de Soporte (SVM)**: Algoritmo de clasificación que encuentra el hiperplano óptimo que separa las clases de datos de forma que maximiza la distancia entre los puntos más cercanos de ambas clases. También puede ser utilizado para regresión.\n",
        "\n",
        "\n",
        "-\n",
        "### **Análisis de Resultados:**\n",
        "\n",
        "**Explicación de los valores de G-mean:**\n",
        "\n",
        "La métrica **G-mean (Geometric Mean)** es una medida importante cuando se trabaja con datos desbalanceados, ya que equilibra la tasa de aciertos en las clases mayoritaria y minoritaria. G-mean es la raíz cuadrada del producto de las tasas de sensibilidad (recall) y especificidad. En otras palabras, penaliza modelos que predicen muy bien una clase (como la mayoritaria) a costa de predecir mal la otra (la minoritaria), ofreciendo un equilibrio entre ambas.\n",
        "\n",
        "Valores cercanos a **1** indican un buen desempeño en ambas clases, mientras que valores más bajos indican que el modelo no está logrando un buen equilibrio entre la clase mayoritaria y la minoritaria.\n",
        "\n",
        "- **Regresión Logística (LR)**:\n",
        "\t- G-mean Test: 0.816 (0.030)\n",
        "\t- G-mean Train: 0.832 (0.007)\n",
        "  - Interpretación: La Regresión Logística muestra un buen equilibrio entre las clases en el conjunto de prueba (0.816) y entrenamiento (0.832), con una pequeña diferencia entre ambos. Esto sugiere que el modelo generaliza bien y no está sobreajustado, lo que es un resultado positivo.\n",
        "\n",
        "- **k-Vecinos más Cercanos (kNN)**:\n",
        "\t- G-mean Test: 0.793 (0.021)\n",
        "\t- G-mean Train: 0.814 (0.006)\n",
        "  - Interpretación: El kNN tiene un desempeño aceptable, aunque ligeramente inferior al de la Regresión Logística. La diferencia entre el G-mean de entrenamiento y prueba no es alarmante, pero sugiere que podría estar ligeramente sobreajustado, ya que rinde mejor en el conjunto de entrenamiento.\n",
        "\n",
        "- **Árbol de Decisión (DTree)**:\n",
        "\t- G-mean Test: 0.791 (0.026)\n",
        "\t- G-mean Train: 0.887 (0.009)\n",
        "  - Interpretación: El Árbol de Decisión muestra una diferencia considerable entre los resultados de prueba y entrenamiento, lo que sugiere sobreajuste. El modelo está aprendiendo demasiado bien el conjunto de entrenamiento (0.887) pero no generaliza tan bien al conjunto de prueba (0.791).\n",
        "\n",
        "- **Bosque Aleatorio (RF)**:\n",
        "\t- G-mean Test: 0.813 (0.028)\n",
        "\t- G-mean Train: 0.970 (0.005)\n",
        "  - Interpretación: El Bosque Aleatorio tiene un buen G-mean en el conjunto de prueba (0.813), pero un G-mean excesivamente alto en el conjunto de entrenamiento (0.970), lo que indica un claro sobreajuste. Este modelo ha aprendido demasiado bien los datos de entrenamiento y no generaliza tan bien.\n",
        "\n",
        "- **XGBoost**:\n",
        "\t- G-mean Test: 0.816 (0.023)\n",
        "\t- G-mean Train: 0.970 (0.005)\n",
        "  - Interpretación: XGBoost tiene uno de los mejores resultados en el conjunto de prueba (0.816), pero como el Bosque Aleatorio, su rendimiento en el conjunto de entrenamiento es extremadamente alto (0.970), lo que indica un sobreajuste significativo. A pesar de su buen desempeño, esto debe manejarse para evitar que el modelo se ajuste demasiado a los datos de entrenamiento.\n",
        "\n",
        "- **Perceptrón Multicapa (MLP)**:\n",
        "\t- G-mean Test: 0.813 (0.026)\n",
        "\t- G-mean Train: 0.831 (0.008)\n",
        "  - Interpretación: El MLP muestra un buen equilibrio con resultados similares en el conjunto de prueba (0.813) y entrenamiento (0.831). La diferencia entre ambos conjuntos es mínima, lo que sugiere que el modelo no está sobreajustado y generaliza bien.\n",
        "\n",
        "- **Máquina de Vectores de Soporte (SVM)**:\n",
        "\t- G-mean Test: 0.822 (0.030)\n",
        "\t- G-mean Train: 0.840 (0.007)\n",
        "  - Interpretación: La SVM tiene un desempeño sólido con un buen G-mean tanto en el conjunto de prueba (0.822) como en el de entrenamiento (0.840), lo que indica una buena capacidad de generalización y un equilibrio entre ambas clases.\n",
        "\n",
        "\n",
        "-\n",
        "### **Mejor Modelo:**\n",
        "\n",
        "En conclusión, los modelos con mejor rendimiento y que demostraron ser los más robustos son:\n",
        "\n",
        "- **Máquina de Vectores de Soporte (SVM)**: Este modelo ofrece un buen balance entre los resultados de prueba (0.822) y entrenamiento (0.840), lo que demuestra su capacidad para generalizar bien sin caer en el sobreajuste. Su habilidad para encontrar el hiperplano óptimo que maximiza la separación entre clases lo convierte en una opción confiable en contextos de clasificación con desbalance de clases.\n",
        "\n",
        "- **Regresión Logística (LR-Elastic)**: La Regresión Logística también mostró un excelente desempeño, con un G-mean de 0.816 en el conjunto de prueba y 0.832 en el conjunto de entrenamiento. Este resultado indica que el modelo generaliza bien y no muestra señales de sobreajuste, lo que lo hace adecuado para problemas de clasificación como este.\n",
        "\n",
        "Ambos modelos, SVM y LR, mostraron ser robustos, equilibrados y capaces de manejar adecuadamente el desbalance de clases. Son modelos confiables que pueden ser implementados en aplicaciones del mundo real, donde la precisión y la capacidad de generalización son cruciales.\n",
        "\n",
        "\n",
        "-\n",
        "### **Conclusión General:**\n",
        "\n",
        "La actividad permitió comparar múltiples modelos y técnicas para abordar un problema de clasificación con datos desbalanceados en el contexto del riesgo crediticio. Aunque XGBoost mostró el mejor desempeño en términos de métricas en el conjunto de prueba, su tendencia al sobreajuste sugiere que no es la opción más confiable sin ajustes adicionales.\n",
        "\n",
        "La Máquina de Vectores de Soporte (SVM) y la Regresión Logística emergen como los modelos más balanceados, ofreciendo un buen desempeño y capacidad de generalización. Esto resalta la importancia de considerar no solo las métricas de desempeño sino también la estabilidad y robustez del modelo al momento de seleccionar la mejor opción para implementación.\n",
        "\n",
        "Finalmente, la experiencia destaca la relevancia de manejar adecuadamente el desbalance de clases y de utilizar técnicas de validación apropiadas para obtener modelos confiables y aplicables en contextos reales.\n",
        "\n",
        "\n",
        "-\n",
        "### **Referencias:**\n",
        "\n",
        "- Alam, T. M., Shaukat, K., Hameed, I. A., Luo, S., Sarwar, M. U., Shabbir, S., Li, J., & Khushi, M. (2020). An investigation of credit card default prediction in the imbalanced datasets. IEEE Access, 8, 201173–201198. Disponible en: https://ieeexplore.ieee.org/document/9239944\n",
        "\n",
        "- Anzai, Y. (2012). Pattern Recognition and Machine Learning. Morgan Kaufmann. Disponible en: https://biblioteca.tec.mx/oreilly\n",
        "\n",
        "- Huyen, C. (s. f.). Designing machine learning systems. O’Reilly Online Learning. https://learning.oreilly.com/library/view/designing-machine-learning/9781098107956/ch04.html\n",
        "\n",
        "- Abhishek, K., & Abdelaziz, M. (s. f.). Machine Learning for Imbalanced Data. O’Reilly Online Learning. https://learning.oreilly.com/library/view/machine-learning-for/9781801070836/B17259_01.xhtml#_idParaDest-20\n",
        "\n",
        "- RandomForestClassifier. (s. f.). Scikit-learn. https://scikit-learn.org/dev/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
        "\n",
        "- Cómo funciona el algoritmo XGBoost—ArcGIS Pro | Documentación. (s. f.). https://pro.arcgis.com/es/pro-app/latest/tool-reference/geoai/how-xgboost-works.htm#:~:text=XGBoost%20es%20la%20abreviatura%20de,aleatorio%20y%20refuerzo%20de%20gradientes.\n",
        "\n",
        "- XGBoost Documentation — xgboost 2.1.1 documentation. (s. f.). https://xgboost.readthedocs.io/en/stable/\n",
        "\n",
        "- Hu, Y., Yang, L., Chen, L., & Zhu, S. (2020). Research on a customer churn combination prediction model based on decision tree and neural network. En 2020 IEEE 5th International Conference on Cloud Computing and Big Data Analytics (ICCCBDA) (pp. 129–132). IEEE. https://doi.org/10.1109/ICCCBDA49378.2020.9095611\n",
        "\n",
        "- Tecnológico de Monterrey. (2024). MNA_IAyAA_semana_5_y_6_Actividad_sept_2024.pdf. [Material de clase]. Curso Inteligencia Artificial y Aprendizaje Automático (Grupo 10), impartido por el Dr. Luis Eduardo Falcón Morales.\n",
        "\n",
        "- Tecnológico de Monterrey. (2024). MNA_IAyAA_Titanic_semanas_5y6.ipynb. [Material complementario]. Curso Inteligencia Artificial y Aprendizaje Automático (Grupo 10), impartido por el Dr. Luis Eduardo Falcón Morales.\n",
        "\n",
        "- Tecnológico de Monterrey. (2024). MNA_IAyAA_semana_6_Arboles_de_decision_y_BosqueAleatorio_teoria-1.pdf. [Material de clase]. Curso Inteligencia Artificial y Aprendizaje Automático (Grupo 10), impartido por el Dr. Luis Eduardo Falcón Morales.\n",
        "\n",
        "- Universidad de California, Irvine. (s.f.). South German Credit Data Set. Recuperado en octubre de 2024 de https://archive.ics.uci.edu/dataset/522/south+german+credit\n",
        "\n",
        "\n",
        "++++++++ Termina la sección de agregar texto +++++++++++"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-tW_CdUYMdl"
      },
      "source": [
        ">> ### **Fin de la Actividad de las Semanas 5 y 6.**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
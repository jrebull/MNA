{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBbWMn9ebmi8"
      },
      "source": [
        "# **Maestr铆a en Inteligencia Artificial Aplicada**\n",
        "\n",
        "## **Curso: Inteligencia Artificial y Aprendizaje Autom谩tico**\n",
        "\n",
        "### Tecnol贸gico de Monterrey\n",
        "\n",
        "### Prof Luis Eduardo Falc贸n Morales\n",
        "\n",
        "## **Actividad de las Semanas 5 y 6**\n",
        "### **Problema de asignaci贸n de cr茅ditos: South German Dataset.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiwEw8XsZG2W"
      },
      "source": [
        "## **Nombres y matr铆culas:**\n",
        "\n",
        "\n",
        " Jossie Paola Jim茅nez Rivera   ★ A01795961\n",
        "\n",
        " Javier Augusto Rebull Saucedo ★ A01795838\n",
        "\n",
        " Nancy Teresa Zapi茅n Garc铆a    ★ A01795907\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUxxkjE6shkH"
      },
      "source": [
        "# **Parte I: Partici贸n, an谩lisis y pre-procesamiento de los datos.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a08Di3GjkL1Y"
      },
      "source": [
        "## **Ejercicio 1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6VGEpE4SblfD"
      },
      "outputs": [],
      "source": [
        "# Aqu铆 deber谩s incluir todas las librer铆as que requieras durante esta actividad:\n",
        "\n",
        "#Para cargar archivos\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Para manipular datos\n",
        "import numpy as np  # Biblioteca para realizar operaciones num茅ricas y trabajar con arreglos multidimensionales.\n",
        "import pandas as pd  # Biblioteca para manipulaci贸n y an谩lisis de datos, ofrece estructuras como DataFrame y Series.\n",
        "\n",
        "# Ejercicio 3.\n",
        "from sklearn.model_selection import train_test_split  # Funci贸n para dividir los datos en conjuntos de entrenamiento y prueba.\n",
        "\n",
        "# Ejercicio 5.\n",
        "from sklearn.pipeline import Pipeline  # Clase que ayuda a ensamblar varios pasos de procesamiento y modelado en una secuencia.\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, OrdinalEncoder  # Herramientas para la transformaci贸n de caracter铆sticas: escalado y codificaci贸n de variables categ贸ricas.\n",
        "from sklearn.compose import ColumnTransformer  # Permite aplicar diferentes transformaciones a diferentes columnas en un conjunto de datos.\n",
        "from sklearn.impute import SimpleImputer  # Rellena valores faltantes en los datos seg煤n una estrategia espec铆fica (como la media, mediana, moda).\n",
        "\n",
        "# Ejercicio 7.\n",
        "from sklearn.linear_model import LogisticRegression  # Modelo de regresi贸n log铆stica para problemas de clasificaci贸n binaria y multiclase.\n",
        "from sklearn.tree import DecisionTreeClassifier  # Modelo de clasificaci贸n basado en 谩rboles de decisi贸n.\n",
        "from sklearn.neighbors import KNeighborsClassifier  # Algoritmo de clasificaci贸n basado en vecinos m谩s cercanos.\n",
        "from sklearn.ensemble import RandomForestClassifier  # Modelo de ensamble basado en m煤ltiples 谩rboles de decisi贸n para mejorar la precisi贸n.\n",
        "from xgboost import XGBClassifier  # Modelo de clasificaci贸n de gradiente boosting basado en 谩rboles, conocido por su alto rendimiento.\n",
        "from sklearn.neural_network import MLPClassifier  # Modelo de red neuronal multicapa para clasificaci贸n.\n",
        "from sklearn.svm import SVC  # M谩quina de vectores de soporte para clasificaci贸n.\n",
        "\n",
        "# Para conjuntos desbalanceados\n",
        "from imblearn.over_sampling import SMOTE, KMeansSMOTE  # T茅cnicas de sobremuestreo para equilibrar clases desbalanceadas en problemas de clasificaci贸n.\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold, cross_validate  # M茅todos para validaci贸n cruzada y divisi贸n estratificada repetida en conjuntos de datos.\n",
        "from sklearn.metrics import make_scorer  # Funci贸n que permite crear m茅tricas personalizadas para la evaluaci贸n de modelos.\n",
        "from imblearn.metrics import geometric_mean_score  # M茅trica de rendimiento para conjuntos de datos desbalanceados, basada en la media geom茅trica."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "K3gUzoM3iRkt"
      },
      "outputs": [],
      "source": [
        "# Si se desean comentar algunos de los Warnings.\n",
        "import warnings  # M贸dulo para controlar los warnings que surgen durante la ejecuci贸n del c贸digo.\n",
        "warnings.filterwarnings('ignore')  # Esta l铆nea desactiva la visualizaci贸n de warnings en el c贸digo. Se usa para evitar que se impriman mensajes de advertencia que no sean cr铆ticos y as铆 tener una salida"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 725
        },
        "id": "ppyf8TTgb9zq",
        "outputId": "71e97a0c-4ff0-4004-9a5d-cd1163b9d5a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                            0     1    2     3     4\n",
              "status                      1     1    2     1     1\n",
              "duration                   18     9   12    12    12\n",
              "credit_history              4     4    2     4     4\n",
              "purpose                     2     0    9     0     0\n",
              "amount                   1049  2799  841  2122  2171\n",
              "savings                     1     1    2     1     1\n",
              "employment_duration         2     3    4     3     3\n",
              "installment_rate            4     2    2     3     4\n",
              "personal_status_sex         2     3    2     3     3\n",
              "other_debtors               1     1    1     1     1\n",
              "present_residence           4     2    4     2     4\n",
              "property                    2     1    1     1     2\n",
              "age                        21    36   23    39    38\n",
              "other_installment_plans     3     3    3     3     1\n",
              "housing                     1     1    1     1     2\n",
              "number_credits              1     2    1     2     2\n",
              "job                         3     3    2     2     2\n",
              "people_liable               2     1    2     1     2\n",
              "telephone                   1     1    1     1     1\n",
              "foreign_worker              2     2    2     1     1\n",
              "credit_risk                 1     1    1     1     1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dbbe65aa-9c88-4bdc-b526-5abef20e3c50\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>status</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>duration</th>\n",
              "      <td>18</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>credit_history</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>purpose</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>amount</th>\n",
              "      <td>1049</td>\n",
              "      <td>2799</td>\n",
              "      <td>841</td>\n",
              "      <td>2122</td>\n",
              "      <td>2171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>savings</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>employment_duration</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>installment_rate</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>personal_status_sex</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>other_debtors</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>present_residence</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>property</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age</th>\n",
              "      <td>21</td>\n",
              "      <td>36</td>\n",
              "      <td>23</td>\n",
              "      <td>39</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>other_installment_plans</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>housing</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>number_credits</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>job</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>people_liable</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>telephone</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>foreign_worker</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>credit_risk</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dbbe65aa-9c88-4bdc-b526-5abef20e3c50')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dbbe65aa-9c88-4bdc-b526-5abef20e3c50 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dbbe65aa-9c88-4bdc-b526-5abef20e3c50');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-479039f9-e5a5-4057-b87e-aef5515b99f6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-479039f9-e5a5-4057-b87e-aef5515b99f6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-479039f9-e5a5-4057-b87e-aef5515b99f6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Carga y renombra los nombres de las columnas del alem谩n al ingl茅s y desplegamos\n",
        "# de nuevo el DataFrame para ver el resultado obtenido:\n",
        "\n",
        "# ************* Incluye aqu铆 tu c贸digo:*****************************\n",
        "# NOTA: Tanto aqu铆 como en lo sucesivo, \"None\" puede indicar una o varias l铆neas de c贸digo.\n",
        "\n",
        "drive.mount('/content/drive')  # Monta Google Drive para acceder a archivos desde Colab.\n",
        "\n",
        "DIR = '/content/drive/MyDrive/TecMTY/septiembre noviembre 2024/IA y ML/Semana 5 y 6'\n",
        "os.chdir(DIR)  # Cambia el directorio a la ubicaci贸n del archivo en Google Drive.\n",
        "\n",
        "# Lectura del archivo .asc\n",
        "df = pd.read_csv('SouthGermanCredit.asc', sep=' ')  # Lee el archivo de cr茅dito alem谩n con separaci贸n por espacio.\n",
        "\n",
        "# Renombra columnas de Alem谩n a Ingl茅s\n",
        "columns = [\n",
        "    'status',                  # Status (laufkont)\n",
        "    'duration',                # Duration (laufzeit)\n",
        "    'credit_history',          # Credit history (moral)\n",
        "    'purpose',                 # Purpose (verw)\n",
        "    'amount',                  # Amount (hoehe)\n",
        "    'savings',                 # Savings (sparkont)\n",
        "    'employment_duration',     # Employment duration (beszeit)\n",
        "    'installment_rate',        # Installment rate (rate)\n",
        "    'personal_status_sex',     # Personal status sex (famges)\n",
        "    'other_debtors',           # Other debtors (buerge)\n",
        "    'present_residence',       # Present residence (wohnzeit)\n",
        "    'property',                # Property (verm)\n",
        "    'age',                     # Age (alter)\n",
        "    'other_installment_plans', # Other installment plans (weitkred)\n",
        "    'housing',                 # Housing (wohn)\n",
        "    'number_credits',          # Number credits (bishkred)\n",
        "    'job',                     # Job (beruf)\n",
        "    'people_liable',           # People liable (pers)\n",
        "    'telephone',               # Telephone (telef)\n",
        "    'foreign_worker',          # Foreign worker (gastarb)\n",
        "    'credit_risk'              # Credit risk (kredit)\n",
        "]\n",
        "\n",
        "# Guarda nuevos nombres de las columnas al DataFrame\n",
        "df.columns = columns  # Asigna la lista 'columns' como nombres de las columnas del DataFrame.\n",
        "\n",
        "# *********** Aqu铆 termina la secci贸n de agregar c贸digo *************\n",
        "\n",
        "df.head().T  # Muestra las primeras filas del DataFrame transpuestas para visualizar mejor los nombres de las columnas y valores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LckYCS8SlnFo"
      },
      "source": [
        "## **Ejercicio 2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tlg8jYbnlqNA",
        "outputId": "3f64842c-cb84-4958-8bed-9cfd06ba31e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "credit_risk\n",
            "0    700\n",
            "1    300\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Realiza a continuaci贸n una transformaci贸n para que la clase negativa (buen cliente)\n",
        "# quede con el valor de 0 y la clase positiva (mal cliente) quede con el valor de 1.\n",
        "\n",
        "# ************* Incluye aqu铆 tu c贸digo:*****************************\n",
        "# Intercambia los valores de la columna 'credit_risk': los buenos clientes (0) pasan a ser 1, y los malos clientes (1) pasan a ser 0.\n",
        "df['credit_risk'] = df['credit_risk'].replace({0:1, 1:0})\n",
        "\n",
        "# *********** Aqu铆 termina la secci贸n de agregar c贸digo *************\n",
        "\n",
        "print(df['credit_risk'].value_counts())  # Muestra el conteo de valores de la columna 'credit_risk' despu茅s de la transformaci贸n para verificar el cambio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQx2lbzTkEsQ"
      },
      "source": [
        "## **Ejercicio 3**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TP5-zdWVczhy",
        "outputId": "d3601a2b-95db-49b1-affc-e0456cea6840"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensiones:\n",
            "Entrenamiento: (700, 20) (700,)\n",
            "Prueba: (300, 20) (300,)\n",
            "\n",
            "Porcentaje clases Positiva:70.00%, y Negativa:30.00%\n"
          ]
        }
      ],
      "source": [
        "# Realiza una partici贸n solicitada de entrenamiento y prueba.\n",
        "# Los nombres de los conjuntos deber谩n ser como se indican en los print de abajo:\n",
        "\n",
        "# ************* Incluye aqu铆 tu c贸digo:*****************************\n",
        "\n",
        "X = df.drop(columns='credit_risk')  # Caracter铆sticas (variables independientes) del conjunto de datos, excluyendo la variable de salida 'credit_risk'.\n",
        "y = df['credit_risk']  # Variable de salida (variable dependiente), en este caso, 'credit_risk'.\n",
        "\n",
        "# El art铆culo sugiere una partici贸n de (70:30), Entrenamiento 70% y Prueba 30%\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.3, stratify=y, random_state=1)\n",
        "# Se realiza la divisi贸n en conjuntos de entrenamiento y prueba, manteniendo la proporci贸n de las clases (stratify) y con un random_state para reproducibilidad.\n",
        "\n",
        "# *********** Aqu铆 termina la secci贸n de agregar c贸digo *************\n",
        "\n",
        "# Mostremos las dimensiones de la partici贸n generada:\n",
        "print(\"Dimensiones:\")  # Se muestran las dimensiones de los conjuntos de entrenamiento y prueba.\n",
        "print(\"Entrenamiento:\", Xtrain.shape, ytrain.shape)  # Dimensiones del conjunto de entrenamiento.\n",
        "print(\"Prueba:\", Xtest.shape, ytest.shape)  # Dimensiones del conjunto de prueba.\n",
        "\n",
        "# Y el porcentaje de cada clase de la variable de salida:\n",
        "tmp = ytrain.sum() / ytrain.shape[0]  # C谩lculo del porcentaje de la clase positiva en el conjunto de entrenamiento.\n",
        "print(\"\\nPorcentaje clases Positiva:%.2f%%, y Negativa:%.2f%%\" % (100*(1-tmp), tmp*100))  # Se imprime el porcentaje de clase positiva y negativa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiiSX3_MdAvr"
      },
      "source": [
        "### **Con base al porcentaje de los niveles de la variable de salida 驴podemos decir que tenemos un problema de datos desbalanceado? 驴Por qu茅?**\n",
        "\n",
        "++++++++ Inicia la secci贸n de agregar texto: +++++++++++\n",
        "\n",
        "Con base en los porcentajes obtenidos, podemos confirmar que existe un desbalance en el conjunto de datos. Del 100% de los datos, el 70% corresponde a la clase positiva (**malos clientes**) y el 30% a la clase negativa (**buenos clientes**). Este desbalance puede impactar negativamente el rendimiento de los modelos de aprendizaje autom谩tico, ya que tienden a ser m谩s efectivos en identificar la clase mayoritaria (malos clientes), mientras que su precisi贸n al predecir la clase minoritaria (buenos clientes) disminuye.\n",
        "\n",
        "Cuando se trabaja con datos desbalanceados, es com煤n que el modelo se ajuste para predecir mejor la clase con mayor representaci贸n (0), lo que puede llevar a errores significativos al identificar casos de la clase minoritaria (1). Esto representa un reto importante para la construcci贸n de modelos que busquen un buen equilibrio entre ambas clases.\n",
        "\n",
        "Para mitigar este problema, es crucial aplicar t茅cnicas adecuadas como el submuestreo de la clase mayoritaria, el sobremuestreo de la clase minoritaria, o el uso de algoritmos dise帽ados para manejar conjuntos de datos desbalanceados. Con estas estrategias, podemos mejorar la capacidad del modelo para identificar correctamente los clientes de la clase minoritaria sin comprometer su rendimiento general.\n",
        "\n",
        "### ++++++++ Termina la secci贸n de agregar texto: +++++++++++"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocmGcSC2j_2x"
      },
      "source": [
        "## **Ejercicio 4**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5J2kIzLYHPZP"
      },
      "outputs": [],
      "source": [
        "# De acuerdo a la informaci贸n de la Tabla 3 del art铆culo de la IEEE\n",
        "# define las variables correspondientes que se indican a continuaci贸n:\n",
        "\n",
        "# ************* Incluye aqu铆 tu c贸digo:*****************************\n",
        "\n",
        "# Variables num茅ricas:\n",
        "lista_paper_num = [\n",
        "    'duration',        # Duraci贸n del cr茅dito\n",
        "    'amount',          # Monto total del cr茅dito\n",
        "    'age',             # Edad del cliente\n",
        "    'peope_liable'     # N煤mero de personas a cargo del cliente\n",
        "]\n",
        "# 4 variables num茅ricas\n",
        "\n",
        "# Variables ordinales:\n",
        "lista_paper_ord = [\n",
        "    'employment_duration',    # Duraci贸n del empleo del cliente\n",
        "    'installment_rate',       # Tasa de las cuotas del cr茅dito\n",
        "    'present_residence',      # Tiempo de residencia en el domicilio actual\n",
        "    'property',               # Tipo de propiedad\n",
        "    'number_credits',         # N煤mero de cr茅ditos anteriores\n",
        "    'job'                     # Ocupaci贸n del cliente\n",
        "]\n",
        "# 6 variables ordinales\n",
        "\n",
        "# Variables nominales:\n",
        "lista_paper_cat = [\n",
        "    'status',                 # Estado del cr茅dito\n",
        "    'credit_history',         # Historial crediticio\n",
        "    'purpose',                # Prop贸sito del cr茅dito\n",
        "    'savings',                # Ahorros del cliente\n",
        "    'personal_status_sex',    # Estado civil y sexo\n",
        "    'other_debtors',          # Otros deudores o avales\n",
        "    'other_installment_plans',# Otros planes de cuotas\n",
        "    'housing',                # Tipo de vivienda\n",
        "    'telephone',              # Disponibilidad de tel茅fono\n",
        "    'foreign_worker'          # Si el cliente es trabajador extranjero\n",
        "]\n",
        "# 10 variables nominales (no se toma en cuenta 'credit_risk')\n",
        "\n",
        "# *********** Aqu铆 termina la secci贸n de agregar c贸digo *************"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zb5bE4WJj8Rw"
      },
      "source": [
        "## **Ejercicio 5**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NvNYiIp9weCm"
      },
      "outputs": [],
      "source": [
        "# Transformaciones que se aplicar谩n a las variables num茅ricas usando la clase Pipeline de sklearn:\n",
        "\n",
        "# ************* Incluye aqu铆 tu c贸digo:*****************************\n",
        "\n",
        "# Variables num茅ricas:\n",
        "numericas_pipe = Pipeline([\n",
        "    (\"impute\", SimpleImputer(strategy=\"median\")),   # Imputar (rellenar) valores faltantes con la mediana de cada variable num茅rica.\n",
        "    (\"standardize\", MinMaxScaler())                 # Escalar los valores num茅ricos para que est茅n en un rango entre 0 y 1, usando MinMaxScaler.\n",
        "])\n",
        "numericas_pipe_nombres = ['duration', 'amount', 'age', 'people_liable']  # Lista de los nombres de las variables num茅ricas a transformar.\n",
        "\n",
        "# Variables categ贸ricas-Nominales:\n",
        "nominales_pipe = Pipeline([\n",
        "    (\"impute\", SimpleImputer(strategy=\"most_frequent\")),  # Imputar valores faltantes con el valor m谩s frecuente (moda) para variables nominales.\n",
        "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", drop=\"first\"))  # Codificaci贸n One-Hot, ignora categor铆as desconocidas y evita la colinealidad (drop=\"first\").\n",
        "])\n",
        "nominales_pipe_nombres = ['status', 'credit_history', 'purpose', 'savings',\n",
        "                          'personal_status_sex', 'other_debtors',\n",
        "                          'other_installment_plans', 'housing', 'telephone', 'foreign_worker']\n",
        "# Lista de los nombres de las variables categ贸ricas nominales a transformar (excluye 'credit_risk').\n",
        "\n",
        "# Variables categ贸ricas-ordinales:\n",
        "ordinales_pipe = Pipeline([\n",
        "    (\"impute\", SimpleImputer(strategy=\"most_frequent\")),  # Imputar valores faltantes con el valor m谩s frecuente.\n",
        "    (\"encoder\", OrdinalEncoder())                        # Codificaci贸n ordinal, que asigna valores num茅ricos ordenados a las categor铆as.\n",
        "])\n",
        "ordinales_pipe_nombres = ['employment_duration', 'installment_rate', 'present_residence',\n",
        "                          'property', 'number_credits', 'job']\n",
        "# Lista de los nombres de las variables categ贸ricas ordinales a transformar.\n",
        "\n",
        "# Conjunta las transformaciones de todo tipo de variable y\n",
        "# deja sin procesar aquellas que hayas decidido no transformar:\n",
        "columnasTransformer = ColumnTransformer(transformers=[\n",
        "    ('num', numericas_pipe, numericas_pipe_nombres),  # Aplica las transformaciones num茅ricas a las variables num茅ricas.\n",
        "    ('ord', ordinales_pipe, ordinales_pipe_nombres),  # Aplica las transformaciones ordinales a las variables categ贸ricas ordinales.\n",
        "    ('nom', nominales_pipe, nominales_pipe_nombres)   # Aplica las transformaciones nominales a las variables categ贸ricas nominales.\n",
        "], remainder='passthrough')  # Mantiene las columnas no especificadas sin procesar ('passthrough').\n",
        "\n",
        "# Explicaci贸n:\n",
        "# - Pipelines: Se utilizan para aplicar secuencias de transformaciones sobre conjuntos de variables. Por ejemplo,\n",
        "#   las variables num茅ricas primero rellenan valores faltantes con la mediana y luego se escalan.\n",
        "# - ColumnTransformer: Permite aplicar diferentes transformaciones a diferentes subconjuntos de variables\n",
        "#   (num茅ricas, ordinales y nominales) al mismo tiempo.\n",
        "# - 'remainder=\"passthrough\"': Indica que las columnas no especificadas en el ColumnTransformer no se transforman\n",
        "#   y se mantienen tal como est谩n.\n",
        "\n",
        "# *********** Aqu铆 termina la secci贸n de agregar c贸digo *************"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJokj9Diyeu0"
      },
      "source": [
        "## **Ejercicio 6**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3lqBiH5wd1e",
        "outputId": "a9ca5a2e-3b1a-4ee5-b7ef-63dd718dedde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensi贸n de las variables de entrada ANTES de las transformaciones: (1000, 20)\n",
            "Dimensi贸n de las variables de entrada DESPUS de las transformaciones: (1000, 41)\n"
          ]
        }
      ],
      "source": [
        "# Como se va a utilizar Validaci贸n-Cruzada, concatena los conjuntos de entrenamiento y prueba\n",
        "# en uno nuevo conjunto aumentado que llamaremos trainval para utilizar como entrenamiento:\n",
        "\n",
        "# ************* Incluye aqu铆 tu c贸digo:**************************\n",
        "\n",
        "# Se concatenan los conjuntos de entrenamiento (Xtrain, ytrain) y prueba (Xtest, ytest) para formar un 煤nico conjunto\n",
        "# combinado llamado Xtraintest y ytraintest. Esto es 煤til cuando se desea entrenar y validar un modelo con\n",
        "# todo el conjunto de datos disponible, aplicando Validaci贸n Cruzada.\n",
        "Xtraintest = pd.concat([Xtrain, Xtest], axis=0)  # Concatena las caracter铆sticas (features) de los conjuntos de entrenamiento y prueba.\n",
        "ytraintest = pd.concat([ytrain, ytest], axis=0)  # Concatena las etiquetas (target) de los conjuntos de entrenamiento y prueba.\n",
        "\n",
        "# *********** Aqu铆 termina la secci贸n de agregar c贸digo *************\n",
        "\n",
        "# Veamos cu谩ntas variables nuevas se introducen con las transformaciones One-Hot-Encoding:\n",
        "Xtmp = Xtraintest.copy()  # Se realiza una copia de Xtraintest para aplicar las transformaciones y no modificar los datos originales.\n",
        "tmp = columnasTransformer.fit_transform(Xtmp)  # Se ajusta y transforma el conjunto de datos usando el ColumnTransformer, que aplica One-Hot-Encoding y otras transformaciones.\n",
        "print(\"Dimensi贸n de las variables de entrada ANTES de las transformaciones:\", Xtmp.shape)  # Imprime la dimensi贸n original del conjunto de datos antes de las transformaciones.\n",
        "print(\"Dimensi贸n de las variables de entrada DESPUS de las transformaciones:\", tmp.shape)  # Imprime la dimensi贸n del conjunto de datos despu茅s de aplicar las transformaciones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZxyRbHL0gNF"
      },
      "source": [
        "## **Ejercicio 7**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hdi7AAtwd5G",
        "outputId": "9ebe6f3d-5363-4b94-977c-978226cef4a6",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> LR\n",
            "\t test_miaccuracy 0.817 (0.029)\n",
            "\t train_miaccuracy 0.832 (0.007)\n",
            "\t test_miprecision 0.827 (0.034)\n",
            "\t train_miprecision 0.845 (0.010)\n",
            "\t test_mirecall 0.803 (0.036)\n",
            "\t train_mirecall 0.813 (0.007)\n",
            "\t test_mifi 0.814 (0.030)\n",
            "\t train_mifi 0.829 (0.007)\n",
            "\t test_miauc 0.903 (0.021)\n",
            "\t train_miauc 0.921 (0.005)\n",
            "\t test_migmean 0.816 (0.030)\n",
            "\t train_migmean 0.832 (0.007)\n",
            ">> kNN\n",
            "\t test_miaccuracy 0.795 (0.020)\n",
            "\t train_miaccuracy 0.817 (0.006)\n",
            "\t test_miprecision 0.840 (0.022)\n",
            "\t train_miprecision 0.865 (0.011)\n",
            "\t test_mirecall 0.731 (0.032)\n",
            "\t train_mirecall 0.751 (0.008)\n",
            "\t test_mifi 0.781 (0.023)\n",
            "\t train_mifi 0.804 (0.006)\n",
            "\t test_miauc 0.881 (0.022)\n",
            "\t train_miauc 0.907 (0.005)\n",
            "\t test_migmean 0.793 (0.021)\n",
            "\t train_migmean 0.814 (0.006)\n",
            ">> DTree\n",
            "\t test_miaccuracy 0.792 (0.026)\n",
            "\t train_miaccuracy 0.888 (0.009)\n",
            "\t test_miprecision 0.802 (0.034)\n",
            "\t train_miprecision 0.910 (0.021)\n",
            "\t test_mirecall 0.777 (0.039)\n",
            "\t train_mirecall 0.862 (0.030)\n",
            "\t test_mifi 0.789 (0.027)\n",
            "\t train_mifi 0.885 (0.010)\n",
            "\t test_miauc 0.853 (0.023)\n",
            "\t train_miauc 0.967 (0.004)\n",
            "\t test_migmean 0.791 (0.026)\n",
            "\t train_migmean 0.887 (0.009)\n",
            ">> RF\n",
            "\t test_miaccuracy 0.819 (0.024)\n",
            "\t train_miaccuracy 0.971 (0.005)\n",
            "\t test_miprecision 0.899 (0.019)\n",
            "\t train_miprecision 1.000 (0.000)\n",
            "\t test_mirecall 0.719 (0.051)\n",
            "\t train_mirecall 0.942 (0.009)\n",
            "\t test_mifi 0.798 (0.033)\n",
            "\t train_mifi 0.970 (0.005)\n",
            "\t test_miauc 0.907 (0.018)\n",
            "\t train_miauc 0.999 (0.000)\n",
            "\t test_migmean 0.813 (0.028)\n",
            "\t train_migmean 0.970 (0.005)\n",
            ">> XGBoost\n",
            "\t test_miaccuracy 0.818 (0.023)\n",
            "\t train_miaccuracy 0.971 (0.005)\n",
            "\t test_miprecision 0.855 (0.028)\n",
            "\t train_miprecision 0.986 (0.004)\n",
            "\t test_mirecall 0.766 (0.034)\n",
            "\t train_mirecall 0.954 (0.009)\n",
            "\t test_mifi 0.808 (0.026)\n",
            "\t train_mifi 0.970 (0.005)\n",
            "\t test_miauc 0.906 (0.019)\n",
            "\t train_miauc 0.997 (0.001)\n",
            "\t test_migmean 0.816 (0.023)\n",
            "\t train_migmean 0.970 (0.005)\n",
            ">> MLP\n",
            "\t test_miaccuracy 0.813 (0.026)\n",
            "\t train_miaccuracy 0.831 (0.008)\n",
            "\t test_miprecision 0.817 (0.028)\n",
            "\t train_miprecision 0.839 (0.013)\n",
            "\t test_mirecall 0.808 (0.036)\n",
            "\t train_mirecall 0.819 (0.011)\n",
            "\t test_mifi 0.812 (0.027)\n",
            "\t train_mifi 0.829 (0.007)\n",
            "\t test_miauc 0.903 (0.021)\n",
            "\t train_miauc 0.921 (0.005)\n",
            "\t test_migmean 0.813 (0.026)\n",
            "\t train_migmean 0.831 (0.008)\n",
            ">> SVM\n",
            "\t test_miaccuracy 0.823 (0.030)\n",
            "\t train_miaccuracy 0.840 (0.007)\n",
            "\t test_miprecision 0.840 (0.033)\n",
            "\t train_miprecision 0.859 (0.010)\n",
            "\t test_mirecall 0.798 (0.038)\n",
            "\t train_mirecall 0.814 (0.011)\n",
            "\t test_mifi 0.818 (0.031)\n",
            "\t train_mifi 0.836 (0.007)\n",
            "\t test_miauc 0.903 (0.022)\n",
            "\t train_miauc 0.919 (0.005)\n",
            "\t test_migmean 0.822 (0.030)\n",
            "\t train_migmean 0.840 (0.007)\n"
          ]
        }
      ],
      "source": [
        "# Definimos a continuaci贸n la funci贸n que llamamos \"mis_modelos\" que incluye\n",
        "# todos los modelos que deseamos comparar en el ejercicio.\n",
        "\n",
        "def mis_modelos():\n",
        "    # Inicializamos listas para almacenar los modelos y sus nombres\n",
        "    modelos, nombres = list(), list()\n",
        "\n",
        "    # ************* Incluye aqu铆 tu c贸digo:**************************\n",
        "    #\n",
        "    # Deber谩s incluir en cada modelo los argumentos que consideres\n",
        "    # adecuados para que cada uno converja y no est茅 sobreentrenado\n",
        "    # con respecto a la m茅trica de la exactitud (accuracy).\n",
        "\n",
        "    # Regresi贸n Log铆stica - Logistic Regression (LR):\n",
        "    modelos.append(LogisticRegression(penalty='elasticnet',\n",
        "                                      solver='saga',\n",
        "                                      tol=0.0001,         # Tolerancia\n",
        "                                      fit_intercept=True,\n",
        "                                      max_iter=2000,\n",
        "                                      C=10,\n",
        "                                      l1_ratio=0.34,\n",
        "                                      random_state=1))\n",
        "    nombres.append('LR')\n",
        "\n",
        "    # k-Vecinos m谩s Cercanos - k-Nearest-Neighbors (kNN):\n",
        "    modelos.append(KNeighborsClassifier(n_neighbors=20,\n",
        "                                        p=1,\n",
        "                                        leaf_size=35,\n",
        "                                        n_jobs=-1,\n",
        "                                        weights=\"uniform\"))\n",
        "    nombres.append('kNN')\n",
        "\n",
        "    # rbol de Decisiones - DecisionTree (DTree):\n",
        "    modelos.append(DecisionTreeClassifier(criterion=\"entropy\",\n",
        "                                          max_depth=10,\n",
        "                                          min_samples_split=15,\n",
        "                                          random_state=1))\n",
        "    nombres.append('DTree')\n",
        "\n",
        "    # Bosque Aleatorio - RandomForest (RF):\n",
        "    modelos.append(RandomForestClassifier(n_estimators=200,\n",
        "                                          criterion=\"entropy\",\n",
        "                                          max_features=\"sqrt\",\n",
        "                                          random_state=1,\n",
        "                                          max_depth=10))\n",
        "    nombres.append('RF')\n",
        "\n",
        "    # XGBoost:\n",
        "    modelos.append(XGBClassifier(random_state=1,\n",
        "                                 tree_method=\"hist\",\n",
        "                                 learning_rate=0.05,\n",
        "                                 max_depth=7))\n",
        "    nombres.append('XGBoost')\n",
        "\n",
        "    # Red Neuronal de Perceptr贸n Multicapa - MLP:\n",
        "    modelos.append(MLPClassifier(solver=\"adam\",\n",
        "                                 random_state=1,\n",
        "                                 hidden_layer_sizes=32,\n",
        "                                 activation=\"identity\",\n",
        "                                 max_iter=2500,\n",
        "                                 alpha=0.001))\n",
        "    nombres.append('MLP')\n",
        "\n",
        "    # M谩quina de Vectores de Soporte - SVM:\n",
        "    modelos.append(SVC(C=14,\n",
        "                       kernel=\"linear\",\n",
        "                       tol=0.0001))\n",
        "    nombres.append('SVM')\n",
        "\n",
        "    return modelos, nombres\n",
        "\n",
        "# T茅cnica de submuestreo (undersampling) y/o sobremuestreo (oversampling) utilizada:\n",
        "mi_uoSampling = KMeansSMOTE(random_state=1, k_neighbors=6, n_jobs=-1)\n",
        "\n",
        "# Aplicamos el sobremuestreo a los datos de entrenamiento:\n",
        "Xtv_uo, ytv_uo = mi_uoSampling.fit_resample(Xtraintest, ytraintest)\n",
        "\n",
        "# *********** Aqu铆 termina la secci贸n de agregar c贸digo *******************\n",
        "\n",
        "# Entrenamos cada uno de los modelos y desplegamos las m茅tricas de Train y Validation (Val).\n",
        "# NOTA: Observa que el m茅todo de Validaci贸n-Cruzada llama a los resultados de \"validation\" como \"test\".\n",
        "\n",
        "modelos, nombres = mis_modelos()  # Llamamos a la funci贸n para obtener los modelos y nombres\n",
        "resultados = list()\n",
        "\n",
        "# Iteramos sobre cada modelo para entrenarlo y evaluar su rendimiento.\n",
        "for i in range(len(modelos)):\n",
        "    # Definimos el pipeline con las transformaciones y los modelos\n",
        "    pipeline = Pipeline(steps=[('ct', columnasTransformer), ('m', modelos[i])])\n",
        "\n",
        "    # Aplicamos validaci贸n-cruzada con 5 divisiones repetidas 3 veces\n",
        "    micv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=5)\n",
        "\n",
        "    # Definimos las m茅tricas que deseamos recuperar\n",
        "    mismetricas = {\n",
        "        'miaccuracy': 'accuracy',\n",
        "        'miprecision': 'precision',\n",
        "        'mirecall': 'recall',\n",
        "        'mifi': 'f1',\n",
        "        'miauc': 'roc_auc',\n",
        "        'migmean': make_scorer(geometric_mean_score)\n",
        "    }\n",
        "\n",
        "    # Entrenamos el modelo usando validaci贸n cruzada\n",
        "    scores = cross_validate(pipeline, Xtv_uo, ytv_uo, scoring=mismetricas, cv=micv, return_train_score=True)\n",
        "\n",
        "    # Guardamos los resultados del modelo para an谩lisis posteriores\n",
        "    resultados.append(scores)\n",
        "\n",
        "    # Desplegamos las m茅tricas para verificar posibles problemas de subentrenamiento o sobreentrenamiento\n",
        "    print('>> %s' % nombres[i])\n",
        "    for j, k in enumerate(list(scores.keys())):\n",
        "        if j > 1:\n",
        "            print('\\t %s %.3f (%.3f)' % (k, np.mean(scores[k]), np.std(scores[k])))\n",
        "\n",
        "# El c贸digo entrena cada uno de los modelos, aplica validaci贸n cruzada y muestra las m茅tricas\n",
        "# para evaluar el rendimiento del modelo en los datos de entrenamiento y validaci贸n."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JkGo57zMXqn"
      },
      "source": [
        "## **Ejercicio 8**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n04HnK-ZX4vl"
      },
      "source": [
        "### **Escribe tus conclusiones finales de la actividad.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iVH8hGAgy_N"
      },
      "source": [
        "++++++++ Inicia la secci贸n de agregar texto: +++++++++++\n",
        "\n",
        "### **Conclusiones Finales de la Actividad:**\n",
        "\n",
        "En esta actividad se evaluaron diferentes modelos de aprendizaje autom谩tico y se implementaron t茅cnicas de sobre-muestreo (SMOTE) para abordar el problema de desbalance de clases. El desbalance de clases, donde la clase mayoritaria (buenos clientes) representa el 70% y la clase minoritaria (malos clientes) el 30%, puede afectar negativamente el rendimiento de los modelos, ya que tienden a priorizar la clase mayoritaria.\n",
        "\n",
        "El sobre-muestreo, como SMOTE, a帽ade ejemplos sint茅ticos a la clase minoritaria para equilibrar la distribuci贸n de clases sin perder datos de la clase mayoritaria. Aunque esta t茅cnica es 煤til, puede incrementar los tiempos de entrenamiento y el uso de memoria, adem谩s de aumentar el riesgo de sobreajuste, especialmente en conjuntos de datos peque帽os. Por otro lado, el submuestreo, que reduce la clase mayoritaria, es m谩s eficiente en cuanto a memoria y tiempo, pero puede llevar a la p茅rdida de informaci贸n valiosa, por lo que no es recomendable en datasets peque帽os.\n",
        "\n",
        "\n",
        "-\n",
        "\n",
        "\n",
        "Los modelos implementados fueron:\n",
        "\n",
        "- **Regresi贸n Log铆stica (LR)**: Algoritmo supervisado para problemas de clasificaci贸n binaria que predice probabilidades seg煤n las caracter铆sticas del conjunto de datos, aplicando una regresi贸n lineal con una salida de 0 o 1.\n",
        "  \n",
        "- **k-Vecinos m谩s Cercanos (kNN)**: Algoritmo utilizado para clasificaci贸n y regresi贸n, que predice la variable de salida basada en los K vecinos m谩s cercanos. El valor de K es clave para ajustar el modelo.\n",
        "\n",
        "- **rbol de Decisi贸n (DTree)**: Algoritmo de clasificaci贸n y regresi贸n que divide el conjunto de datos en subconjuntos basados en caracter铆sticas, creando un 谩rbol de decisiones que facilita las predicciones.\n",
        "\n",
        "- **Bosque Aleatorio (RF)**: Algoritmo de ensamble que construye m煤ltiples 谩rboles de decisi贸n en submuestras del conjunto de datos y promedia los resultados para mejorar la precisi贸n y reducir el sobreajuste.\n",
        "\n",
        "- **Extreme Gradient Boosting (XGBoost)**: M茅todo basado en 谩rboles de decisi贸n que mejora el rendimiento mediante el refuerzo de gradientes. Cada 谩rbol se construye para corregir los errores del anterior, continuando hasta que los residuales se minimicen o se alcance el n煤mero m谩ximo de iteraciones.\n",
        "\n",
        "- **Red Neuronal de Perceptr贸n Multicapa (MLP)**: Modelo inspirado en el funcionamiento del cerebro humano, compuesto por m煤ltiples capas de neuronas conectadas que permiten el aprendizaje de patrones complejos.\n",
        "\n",
        "- **M谩quina de Vectores de Soporte (SVM)**: Algoritmo de clasificaci贸n que encuentra el hiperplano 贸ptimo que separa las clases de datos de forma que maximiza la distancia entre los puntos m谩s cercanos de ambas clases. Tambi茅n puede ser utilizado para regresi贸n.\n",
        "\n",
        "\n",
        "-\n",
        "### **An谩lisis de Resultados:**\n",
        "\n",
        "**Explicaci贸n de los valores de G-mean:**\n",
        "\n",
        "La m茅trica **G-mean (Geometric Mean)** es una medida importante cuando se trabaja con datos desbalanceados, ya que equilibra la tasa de aciertos en las clases mayoritaria y minoritaria. G-mean es la ra铆z cuadrada del producto de las tasas de sensibilidad (recall) y especificidad. En otras palabras, penaliza modelos que predicen muy bien una clase (como la mayoritaria) a costa de predecir mal la otra (la minoritaria), ofreciendo un equilibrio entre ambas.\n",
        "\n",
        "Valores cercanos a **1** indican un buen desempe帽o en ambas clases, mientras que valores m谩s bajos indican que el modelo no est谩 logrando un buen equilibrio entre la clase mayoritaria y la minoritaria.\n",
        "\n",
        "- **Regresi贸n Log铆stica (LR)**:\n",
        "\t- G-mean Test: 0.816 (0.030)\n",
        "\t- G-mean Train: 0.832 (0.007)\n",
        "  - Interpretaci贸n: La Regresi贸n Log铆stica muestra un buen equilibrio entre las clases en el conjunto de prueba (0.816) y entrenamiento (0.832), con una peque帽a diferencia entre ambos. Esto sugiere que el modelo generaliza bien y no est谩 sobreajustado, lo que es un resultado positivo.\n",
        "\n",
        "- **k-Vecinos m谩s Cercanos (kNN)**:\n",
        "\t- G-mean Test: 0.793 (0.021)\n",
        "\t- G-mean Train: 0.814 (0.006)\n",
        "  - Interpretaci贸n: El kNN tiene un desempe帽o aceptable, aunque ligeramente inferior al de la Regresi贸n Log铆stica. La diferencia entre el G-mean de entrenamiento y prueba no es alarmante, pero sugiere que podr铆a estar ligeramente sobreajustado, ya que rinde mejor en el conjunto de entrenamiento.\n",
        "\n",
        "- **rbol de Decisi贸n (DTree)**:\n",
        "\t- G-mean Test: 0.791 (0.026)\n",
        "\t- G-mean Train: 0.887 (0.009)\n",
        "  - Interpretaci贸n: El rbol de Decisi贸n muestra una diferencia considerable entre los resultados de prueba y entrenamiento, lo que sugiere sobreajuste. El modelo est谩 aprendiendo demasiado bien el conjunto de entrenamiento (0.887) pero no generaliza tan bien al conjunto de prueba (0.791).\n",
        "\n",
        "- **Bosque Aleatorio (RF)**:\n",
        "\t- G-mean Test: 0.813 (0.028)\n",
        "\t- G-mean Train: 0.970 (0.005)\n",
        "  - Interpretaci贸n: El Bosque Aleatorio tiene un buen G-mean en el conjunto de prueba (0.813), pero un G-mean excesivamente alto en el conjunto de entrenamiento (0.970), lo que indica un claro sobreajuste. Este modelo ha aprendido demasiado bien los datos de entrenamiento y no generaliza tan bien.\n",
        "\n",
        "- **XGBoost**:\n",
        "\t- G-mean Test: 0.816 (0.023)\n",
        "\t- G-mean Train: 0.970 (0.005)\n",
        "  - Interpretaci贸n: XGBoost tiene uno de los mejores resultados en el conjunto de prueba (0.816), pero como el Bosque Aleatorio, su rendimiento en el conjunto de entrenamiento es extremadamente alto (0.970), lo que indica un sobreajuste significativo. A pesar de su buen desempe帽o, esto debe manejarse para evitar que el modelo se ajuste demasiado a los datos de entrenamiento.\n",
        "\n",
        "- **Perceptr贸n Multicapa (MLP)**:\n",
        "\t- G-mean Test: 0.813 (0.026)\n",
        "\t- G-mean Train: 0.831 (0.008)\n",
        "  - Interpretaci贸n: El MLP muestra un buen equilibrio con resultados similares en el conjunto de prueba (0.813) y entrenamiento (0.831). La diferencia entre ambos conjuntos es m铆nima, lo que sugiere que el modelo no est谩 sobreajustado y generaliza bien.\n",
        "\n",
        "- **M谩quina de Vectores de Soporte (SVM)**:\n",
        "\t- G-mean Test: 0.822 (0.030)\n",
        "\t- G-mean Train: 0.840 (0.007)\n",
        "  - Interpretaci贸n: La SVM tiene un desempe帽o s贸lido con un buen G-mean tanto en el conjunto de prueba (0.822) como en el de entrenamiento (0.840), lo que indica una buena capacidad de generalizaci贸n y un equilibrio entre ambas clases.\n",
        "\n",
        "\n",
        "-\n",
        "### **Mejor Modelo:**\n",
        "\n",
        "En conclusi贸n, los modelos con mejor rendimiento y que demostraron ser los m谩s robustos son:\n",
        "\n",
        "- **M谩quina de Vectores de Soporte (SVM)**: Este modelo ofrece un buen balance entre los resultados de prueba (0.822) y entrenamiento (0.840), lo que demuestra su capacidad para generalizar bien sin caer en el sobreajuste. Su habilidad para encontrar el hiperplano 贸ptimo que maximiza la separaci贸n entre clases lo convierte en una opci贸n confiable en contextos de clasificaci贸n con desbalance de clases.\n",
        "\n",
        "- **Regresi贸n Log铆stica (LR-Elastic)**: La Regresi贸n Log铆stica tambi茅n mostr贸 un excelente desempe帽o, con un G-mean de 0.816 en el conjunto de prueba y 0.832 en el conjunto de entrenamiento. Este resultado indica que el modelo generaliza bien y no muestra se帽ales de sobreajuste, lo que lo hace adecuado para problemas de clasificaci贸n como este.\n",
        "\n",
        "Ambos modelos, SVM y LR, mostraron ser robustos, equilibrados y capaces de manejar adecuadamente el desbalance de clases. Son modelos confiables que pueden ser implementados en aplicaciones del mundo real, donde la precisi贸n y la capacidad de generalizaci贸n son cruciales.\n",
        "\n",
        "\n",
        "-\n",
        "### **Conclusi贸n General:**\n",
        "\n",
        "La actividad permiti贸 comparar m煤ltiples modelos y t茅cnicas para abordar un problema de clasificaci贸n con datos desbalanceados en el contexto del riesgo crediticio. Aunque XGBoost mostr贸 el mejor desempe帽o en t茅rminos de m茅tricas en el conjunto de prueba, su tendencia al sobreajuste sugiere que no es la opci贸n m谩s confiable sin ajustes adicionales.\n",
        "\n",
        "La M谩quina de Vectores de Soporte (SVM) y la Regresi贸n Log铆stica emergen como los modelos m谩s balanceados, ofreciendo un buen desempe帽o y capacidad de generalizaci贸n. Esto resalta la importancia de considerar no solo las m茅tricas de desempe帽o sino tambi茅n la estabilidad y robustez del modelo al momento de seleccionar la mejor opci贸n para implementaci贸n.\n",
        "\n",
        "Finalmente, la experiencia destaca la relevancia de manejar adecuadamente el desbalance de clases y de utilizar t茅cnicas de validaci贸n apropiadas para obtener modelos confiables y aplicables en contextos reales.\n",
        "\n",
        "\n",
        "-\n",
        "### **Referencias:**\n",
        "\n",
        "- Alam, T. M., Shaukat, K., Hameed, I. A., Luo, S., Sarwar, M. U., Shabbir, S., Li, J., & Khushi, M. (2020). An investigation of credit card default prediction in the imbalanced datasets. IEEE Access, 8, 201173201198. Disponible en: https://ieeexplore.ieee.org/document/9239944\n",
        "\n",
        "- Anzai, Y. (2012). Pattern Recognition and Machine Learning. Morgan Kaufmann. Disponible en: https://biblioteca.tec.mx/oreilly\n",
        "\n",
        "- Huyen, C. (s. f.). Designing machine learning systems. OReilly Online Learning. https://learning.oreilly.com/library/view/designing-machine-learning/9781098107956/ch04.html\n",
        "\n",
        "- Abhishek, K., & Abdelaziz, M. (s. f.). Machine Learning for Imbalanced Data. OReilly Online Learning. https://learning.oreilly.com/library/view/machine-learning-for/9781801070836/B17259_01.xhtml#_idParaDest-20\n",
        "\n",
        "- RandomForestClassifier. (s. f.). Scikit-learn. https://scikit-learn.org/dev/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
        "\n",
        "- C贸mo funciona el algoritmo XGBoostArcGIS Pro | Documentaci贸n. (s. f.). https://pro.arcgis.com/es/pro-app/latest/tool-reference/geoai/how-xgboost-works.htm#:~:text=XGBoost%20es%20la%20abreviatura%20de,aleatorio%20y%20refuerzo%20de%20gradientes.\n",
        "\n",
        "- XGBoost Documentation  xgboost 2.1.1 documentation. (s. f.). https://xgboost.readthedocs.io/en/stable/\n",
        "\n",
        "- Hu, Y., Yang, L., Chen, L., & Zhu, S. (2020). Research on a customer churn combination prediction model based on decision tree and neural network. En 2020 IEEE 5th International Conference on Cloud Computing and Big Data Analytics (ICCCBDA) (pp. 129132). IEEE. https://doi.org/10.1109/ICCCBDA49378.2020.9095611\n",
        "\n",
        "- Tecnol贸gico de Monterrey. (2024). MNA_IAyAA_semana_5_y_6_Actividad_sept_2024.pdf. [Material de clase]. Curso Inteligencia Artificial y Aprendizaje Autom谩tico (Grupo 10), impartido por el Dr. Luis Eduardo Falc贸n Morales.\n",
        "\n",
        "- Tecnol贸gico de Monterrey. (2024). MNA_IAyAA_Titanic_semanas_5y6.ipynb. [Material complementario]. Curso Inteligencia Artificial y Aprendizaje Autom谩tico (Grupo 10), impartido por el Dr. Luis Eduardo Falc贸n Morales.\n",
        "\n",
        "- Tecnol贸gico de Monterrey. (2024). MNA_IAyAA_semana_6_Arboles_de_decision_y_BosqueAleatorio_teoria-1.pdf. [Material de clase]. Curso Inteligencia Artificial y Aprendizaje Autom谩tico (Grupo 10), impartido por el Dr. Luis Eduardo Falc贸n Morales.\n",
        "\n",
        "- Universidad de California, Irvine. (s.f.). South German Credit Data Set. Recuperado en octubre de 2024 de https://archive.ics.uci.edu/dataset/522/south+german+credit\n",
        "\n",
        "\n",
        "++++++++ Termina la secci贸n de agregar texto +++++++++++"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-tW_CdUYMdl"
      },
      "source": [
        ">> ### **Fin de la Actividad de las Semanas 5 y 6.**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}